{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###不同算法准确率\n",
    "* KNN 在k=10时达到了最大准确率，峰值是29.6%\n",
    "* SVM 经过调参之后在测试集上达到了39.2%\n",
    "* Softmax 经过调参之后可以达到37%\n",
    "* 两层神经网络准确率可以达到52.5%\n",
    "* HoG+HSV颜色直方图特征+SVM 调参之后可以达到42.3%\n",
    "* HoG+HSV颜色直方图+两层全连接神经网络准确率可以达到56.8%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###基础知识\n",
    "* 图像分类的pipeline包括数据的收集准备、预处理、特征的提取(可能包含)、模型的训练与参数选择、测试集验证\n",
    "* Numpy中vectorized code要比使用循环计算快，因为numpy底层使用C+BLAS,可以极快地加大运行速度\n",
    "* 不使用核技巧的SVM可以使用次梯度方法(subgradient method)来实现\n",
    "* 二类的LR是softmax的一个特例。Soft的梯度是所有训练样本的线型组合，而SVM只用到在margin以内的样本和正确类本身。\n",
    "* 不同的分类器都存在variance和bias之间的trade-off\n",
    "* high-level representation +简单模型 VS low-level representation+ 复杂模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Coding tips\n",
    "* Python的面向对象也有继承和\"虚函数\"的概念\n",
    "* __init__()相当于构造函数\n",
    "* 函数的参数要加self，相当于显式的this指针\n",
    "* numpy的broadcast是非常好用的特性\n",
    "* 对于简单的分类算法，Python中使用面向对象的方法，类可以有三个接口，构造函数初始化模型，train()进行训练，predict()使用训练好的模型进行预测\n",
    "模型的权值作为类的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###经验\n",
    "* 即使是使用相同的算法，换用不同的数据集时，学习率、正则化权重、学习率衰减等参数也可能相差很大\n",
    "* 在Softmax和SVM中旺往往学习率越小，要取得好结果，对应的正则化权重就要越大"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
